# Consider an entity that appears at some location and performs an activity at
# that location at a given time. The entity may then move to another location
# undetected and reappear by performing another activity. The type of activity
# remains fixed for the entity.
#
# The problem is to attribute the events to each entity.
#
# The number of entities is unknown, but its upper bound can be determined from
# the data as it is simply the number of events in the dataset.
#
# Data is generated that has two variables:
# - Position in an (x,y) coordinate space
# - Time (measured in days)
# - Activity (categorical variable)

from distributions import *


def generate_series(
    initial_location,
    initial_time,
    activity_type,
    number_of_events,
    distance_between_locations,
    time_between_events,
):

    # Series is a list of tuples of (x, y, time, event type)
    series = []

    # Initial event
    x, y = initial_location()
    series.append((x, y, initial_time(), activity_type()))

    for _ in range(1, number_of_events()):
        x_delta, y_delta = distance_between_locations()
        x2, y2 = series[-1][0] + x_delta, series[-1][1] + y_delta

        time2 = series[-1][2] + time_between_events()

        activity = series[-1][3]

        series.append((x2, y2, time2, activity))

    return series


def sort_series_by_time(series, ground_truth):
    """Sort the series and its associated ground truth entity ID by time."""
    assert len(series) == len(ground_truth)

    s = sorted(zip(series, ground_truth), key=lambda x: x[0][2])
    sorted_series, sorted_ground_truth = list(zip(*s))
    sorted_series = list(sorted_series)
    sorted_ground_truth = list(sorted_ground_truth)

    assert len(sorted_series) == len(series)
    assert len(sorted_ground_truth) == len(ground_truth)

    return sorted_series, sorted_ground_truth


def algorithm1(series, max_num_events_per_entity):
    """Randomly assign each report to an entity."""

    n_events = len(series)
    max_entities = n_events  # one event per entity
    min_entities = math.ceil(n_events / max_num_events_per_entity)

    num_entities = discrete_uniform(min_entities, max_entities)()
    entity_idx_gen = discrete_uniform(0, num_entities - 1)

    return [entity_idx_gen() for _ in range(n_events)]


def label_error(ground_truth, actual):

    assert type(ground_truth) == list, f"Expected a list, got {type(ground_truth)}"
    assert type(actual) == list, f"Expected a list, got {type(actual)}"
    assert len(ground_truth) == len(
        actual
    ), f"Expected {len(ground_truth)}, got {len(actual)}"

    min_entity_id = min(actual)
    max_entity_id = max(actual)

    proportions = []

    for entity_idx in range(min_entity_id, max_entity_id + 1):
        # Find all the indices where the actual label reference the entity with
        # index entity_idx
        indices = [i for i, j in enumerate(actual) if j == entity_idx]
        if len(indices) == 0:
            continue

        # Get a list of the ground truth entity IDs
        ground_truth_entities = [ground_truth[i] for i in indices]

        # Find the most common ground truth entity ID
        most_common = np.bincount(ground_truth_entities).argmax()

        # Count how many times the ground truth entity ID occurred
        freq_most_common = sum(
            [1 if idx == most_common else 0 for idx in ground_truth_entities]
        )

        proportions.append(1 - (freq_most_common / len(ground_truth_entities)))

    return np.mean(proportions)


if __name__ == "__main__":

    # Initial location of the events
    initial_location = continuous_uniform_pair(0, 1, 0, 1)

    # Initial time of the events
    initial_time = discrete_uniform(0, 30)

    # Type of activity in the event
    activity_type = categorical({"A": 0.8, "B": 0.1, "C": 0.1})

    # Number of events generated by each entity
    max_num_events_per_entity = 10
    num_events = discrete_uniform(1, max_num_events_per_entity)

    # Distance between locations
    distance_between_locations = multivariate_normal(0.1)

    # Time between evetns
    time_between_events = discrete_uniform(1, 30)

    # Generate a synthetic dataset
    n_entities = 2
    series = []
    ground_truth = []
    for entity_id in range(n_entities):
        entity_series = generate_series(
            initial_location,
            initial_time,
            activity_type,
            num_events,
            distance_between_locations,
            time_between_events,
        )

        ground_truth.extend([entity_id] * len(entity_series))
        series.extend(entity_series)

    # Sort the data based on time
    series, ground_truth = sort_series_by_time(series, ground_truth)

    # Check the error function
    assert label_error(ground_truth, ground_truth) == 0.0

    # Algorithm 1: Random assignment
    labels1 = algorithm1(series, max_num_events_per_entity)
    alg1_error = label_error(ground_truth, labels1)
    print(alg1_error)
