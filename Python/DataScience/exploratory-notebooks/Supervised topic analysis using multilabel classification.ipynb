{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised topic analysis using multilabel classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classifiers seek to predict a single optimal label for each feature vector. Typically, the values 0 or 1 are used to represent the label, although other schemes, such as True/False can be used.\n",
    "\n",
    "A multilabel classifier seeks to predict the optimal labels for each feature vector where the target is no longer a single value, as with a binary classifier, but a vector of binary labels.  For example, consider the problem of classifying images that can contain any of the letters A, B and C. The classifier is trained to recognise the letters and when shown an image with the letters A and C it should predict the labels to be $[1, 0, 1]$.\n",
    "\n",
    "This Jupyter notebook explores the problem of predicting the topics present in a corpus where training data exists as to which topics are present in a given document. A single document can contain words from zero or more topics. This is different from unsupervised topic analysis in that the topics have been defined and the topics present in a document are available, thus a supervised approach can be used. For simplicity, this notebook generates random text data and then different multilabel classification techniques are explored. This allows the relative proportions of the topics present in the texts to be changed and the effect on performance to be measured. The texts generated are not human readable because the generative model is simplistic, but it is sufficient for testing and demonstrating a multilabel classification solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each document is generated using a mixture model. There are three primary components:\n",
    "\n",
    "* Stop words -- high frequency words such as 'a', 'the', 'see'.\n",
    "* Common words -- common English words that are not stop words, such as 'matter', 'found', 'create'.\n",
    "* Topic words -- words derived from a given topic.\n",
    "\n",
    "This work assumes that there are at least two topics of interest. In the code below, three random topics were defined: 'vehicle'; 'internet'; and 'garden'. The topics were chosen because they don't contain overlapping words.\n",
    "\n",
    "The number of stop words in a text $N_{stop}$ is determined by sampling from a Poisson distribution with mean $\\lambda_{stop}$. The number of stop words $N_{stop}$ required for the text are then sampled by randomly selecting stop words (with replacement), which are contained in a pre-defined set.\n",
    "\n",
    "Similarly, the number of common words in a text is determined by sampling from a Poisson distribution with mean $\\lambda_{common}$. $N_{common}$ words are randomly sampled with replacement from the set of all common words.\n",
    "\n",
    "The text can contain words from zero or more topics. The probability that topic $i$ appears in a text is denoted $p_i$ where $0 \\leq p_i \\leq 1$. The presence of the topic in a text is determined by sampling from a Bernoulli distribution with $p_i$. If a topic exists, the number of words randomly selected from the topic (with replacement) is determined by sampling from a Poisson distribution with mean $\\lambda_i$ where $\\lambda_i > 0$.\n",
    "\n",
    "In the model decribed, the topics of interest are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are commonly occurring words that are essentially 'noise'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "# Stop words\n",
    "stop_words = ['a', 'about', 'above', 'across', 'after', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'among', 'an', 'and', 'another', 'any', 'anybody', 'anyone', 'anything', 'anywhere', 'are', 'area', 'areas', 'around', 'as', 'ask', 'asked', 'asking', 'asks', 'at', 'away', 'b', 'back', 'backed', 'backing', 'backs', 'be', 'became', 'because', 'become', 'becomes', 'been', 'before', 'began', 'behind', 'being', 'beings', 'best', 'better', 'between', 'big', 'both', 'but', 'by', 'c', 'came', 'can', 'cannot', 'case', 'cases', 'certain', 'certainly', 'clear', 'clearly', 'come', 'could', 'd', 'did', 'differ', 'different', 'differently', 'do', 'does', 'done', 'down', 'down', 'downed', 'downing', 'downs', 'during', 'e', 'each', 'early', 'either', 'end', 'ended', 'ending', 'ends', 'enough', 'even', 'evenly', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'f', 'face', 'faces', 'fact', 'facts', 'far', 'felt', 'few', 'find', 'finds', 'first', 'for', 'four', 'from', 'full', 'fully', 'further', 'furthered', 'furthering', 'furthers', 'g', 'gave', 'general', 'generally', 'get', 'gets', 'give', 'given', 'gives', 'go', 'going', 'good', 'goods', 'got', 'great', 'greater', 'greatest', 'group', 'grouped', 'grouping', 'groups', 'h', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'herself', 'high', 'high', 'high', 'higher', 'highest', 'him', 'himself', 'his', 'how', 'however', 'i', 'if', 'important', 'in', 'interest', 'interested', 'interesting', 'interests', 'into', 'is', 'it', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kind', 'knew', 'know', 'known', 'knows', 'l', 'large', 'largely', 'last', 'later', 'latest', 'least', 'less', 'let', 'lets', 'like', 'likely', 'long', 'longer', 'longest', 'm', 'made', 'make', 'making', 'man', 'many', 'may', 'me', 'member', 'members', 'men', 'might', 'more', 'most', 'mostly', 'mr', 'mrs', 'much', 'must', 'my', 'myself', 'n', 'necessary', 'need', 'needed', 'needing', 'needs', 'never', 'new', 'new', 'newer', 'newest', 'next', 'no', 'nobody', 'non', 'noone', 'not', 'nothing', 'now', 'nowhere', 'number', 'numbers', 'o', 'of', 'off', 'often', 'old', 'older', 'oldest', 'on', 'once', 'one', 'only', 'open', 'opened', 'opening', 'opens', 'or', 'order', 'ordered', 'ordering', 'orders', 'other', 'others', 'our', 'out', 'over', 'p', 'part', 'parted', 'parting', 'parts', 'per', 'perhaps', 'place', 'places', 'point', 'pointed', 'pointing', 'points', 'possible', 'present', 'presented', 'presenting', 'presents', 'problem', 'problems', 'put', 'puts', 'q', 'quite', 'r', 'rather', 'really', 'right', 'right', 'room', 'rooms', 's', 'said', 'same', 'saw', 'say', 'says', 'second', 'seconds', 'see', 'seem', 'seemed', 'seeming', 'seems', 'sees', 'several', 'shall', 'she', 'should', 'show', 'showed', 'showing', 'shows', 'side', 'sides', 'since', 'small', 'smaller', 'smallest', 'so', 'some', 'somebody', 'someone', 'something', 'somewhere', 'state', 'states', 'still', 'still', 'such', 'sure', 't', 'take', 'taken', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'these', 'they', 'thing', 'things', 'think', 'thinks', 'this', 'those', 'though', 'thought', 'thoughts', 'three', 'through', 'thus', 'to', 'today', 'together', 'too', 'took', 'toward', 'turn', 'turned', 'turning', 'turns', 'two', 'u', 'under', 'until', 'up', 'upon', 'us', 'use', 'used', 'uses', 'v', 'very', 'w', 'want', 'wanted', 'wanting', 'wants', 'was', 'way', 'ways', 'we', 'well', 'wells', 'went', 'were', 'what', 'when', 'where', 'whether', 'which', 'while', 'who', 'whole', 'whose', 'why', 'will', 'with', 'within', 'without', 'work', 'worked', 'working', 'works', 'would', 'x', 'y', 'year', 'years', 'yet', 'you', 'young', 'younger', 'youngest', 'your', 'yours', 'z']\n",
    "stop_words = set(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common words occur frequently, but not so frequently as to be deemed stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770\n"
     ]
    }
   ],
   "source": [
    "# Common words (non-stop words) derived from https://gist.github.com/deekayen/4148741\n",
    "common_words = {'charge', 'view', 'morning', 'especially', 'care', 'happy', 'wrote', 'occur', 'final', 'women', 'offer', 'rain', 'clean', 'nine', 'blow', 'excite', 'shape', 'teach', 'floor', 'black', 'copy', 'car', 'drink', 'quotient', 'practice', 'animal', 'grow', 'proper', 'believe', 'huge', 'segment', 'answer', 'begin', 'force', 'region', 'drive', 'contain', 'house', 'girl', 'board', 'coat', 'clothe', 'energy', 'visit', 'common', 'arrive', 'correct', 'difficult', 'color', 'song', 'person', 'dark', 'exercise', 'flower', 'caught', 'throw', 'anger', 'safe', 'spoke', \"won't\", 'head', 'paper', 'leave', 'neck', 'captain', 'except', 'trade', 'children', 'insect', 'mean', 'field', 'smile', 'voice', 'experience', 'sharp', 'protect', 'store', 'run', 'degree', 'flow', 'control', 'record', 'main', 'syllable', 'left', 'moment', 'ready', 'born', 'table', 'rest', 'winter', 'million', 'string', 'picture', 'example', 'sail', 'party', 'stand', 'true', 'boy', 'beauty', 'front', 'solution', 'cold', 'jump', 'soon', 'triangle', 'study', 'plan', 'special', 'fine', 'appear', 'position', 'type', 'truck', 'tree', 'fall', 'mountain', 'art', 'chart', 'planet', 'set', 'process', 'period', 'broad', 'miss', 'change', 'bright', 'enter', 'clock', 'follow', 'design', 'hill', 'touch', 'consider', 'sugar', 'team', 'third', 'pitch', 'provide', 'story', 'town', 'sight', 'afraid', 'cry', 'subject', 'level', 'please', 'river', 'match', 'held', 'life', 'written', 'help', 'station', 'vary', 'chick', 'die', 'sign', 'lone', 'develop', 'valley', 'rub', 'add', 'law', 'brother', 'hard', 'natural', 'tone', 'land', 'bring', 'break', 'opposite', 'piece', 'wild', 'nor', 'distant', 'indicate', 'dear', 'surprise', 'wall', 'reply', 'neighbor', 'lift', 'circle', 'food', 'moon', 'earth', 'learn', 'loud', 'school', 'shout', 'notice', 'hat', 'sell', 'subtract', 'company', 'pay', 'chance', 'mark', 'material', 'wash', 'range', 'probable', 'lot', 'row', 'gather', 'week', 'lie', 'suffix', 'dance', 'oxygen', 'prepare', 'poor', 'window', 'white', 'nose', 'speech', 'own', 'bread', 'melody', 'idea', 'flat', 'coast', 'gun', 'cat', 'multiply', 'poem', 'double', 'wind', 'metal', 'bit', 'friend', 'stood', 'egg', 'slave', 'sand', 'child', 'real', 'door', 'fresh', 'question', 'shoulder', 'pick', 'thick', 'stay', 'listen', 'seven', 'salt', 'forward', 'forest', 'dead', 'fly', 'locate', 'water', 'shore', 'cost', 'mount', 'numeral', 'feed', 'market', 'ten', 'hunt', 'hour', 'glass', 'cross', 'mass', 'blood', 'scale', 'continent', 'shop', 'look', 'class', 'roll', 'round', 'decimal', 'chord', 'reason', 'chief', 'simple', 'office', 'sent', 'join', 'mix', 'hair', 'finish', 'stick', 'red', 'light', 'dog', 'grand', 'substance', 'wrong', 'sheet', 'unit', 'property', 'live', 'speed', 'symbol', 'drop', 'vowel', 'heat', 'remember', 'shine', 'noon', 'race', 'dad', 'line', 'system', 'noun', 'woman', 'horse', 'blue', 'garden', 'figure', 'electric', 'weight', 'lake', 'warm', 'division', 'call', 'village', 'nation', 'receive', 'character', 'tall', 'soldier', 'reach', 'matter', 'steel', 'found', 'street', 'bat', 'buy', 'motion', 'five', 'soil', 'imagine', 'play', 'score', 'trip', 'skin', 'spot', 'dream', 'pass', 'bird', 'pound', 'crease', 'cow', 'mother', 'wonder', 'watch', 'length', 'section', 'science', 'happen', 'raise', 'eat', 'cloud', 'grew', 'move', 'read', 'stead', 'guess', 'fire', 'milk', 'able', 'tiny', 'road', 'swim', 'shoe', 'wire', 'heard', 'hope', 'block', 'compare', 'human', 'direct', 'sky', 'seed', 'steam', 'allow', 'support', 'form', 'yes', 'bank', 'single', 'claim', 'history', 'list', 'talk', 'strong', 'root', 'produce', 'sat', 'stream', 'cool', 'late', 'space', 'current', 'spell', 'world', 'father', 'ship', 'plural', 'object', 'magnet', 'sun', 'rail', 'else', 'box', 'molecule', 'act', 'wheel', 'job', 'fast', 'cause', 'leg', 'sister', 'gentle', 'desert', 'fell', 'condition', 'south', 'middle', 'guide', 'train', 'son', 'bed', 'chair', 'cotton', 'oh', 'cell', 'enemy', 'self', 'log', 'tire', 'fill', 'power', 'test', 'grass', 'fun', 'ball', 'bear', 'north', 'hundred', 'center', 'modern', 'start', 'inch', 'season', 'top', 'rock', 'deep', 'quick', 'arm', 'stretch', 'path', 'broke', 'teeth', 'near', 'suggest', 'evening', 'check', 'cut', 'plain', 'catch', 'key', 'gray', 'doctor', 'result', 'fit', 'success', 'ring', 'gold', 'noise', 'instrument', 'plant', 'meet', 'basic', 'paint', 'element', 'arrange', 'apple', 'govern', 'green', 'cover', 'expect', 'rise', 'game', 'joy', 'lay', 'burn', 'atom', 'rule', 'thin', 'discuss', 'note', 'fair', 'feel', 'spread', 'trouble', 'smell', 'favor', 'snow', 'mind', 'fish', 'wish', 'divide', 'lead', 'meant', 'name', 'pattern', 'decide', 'ran', 'finger', 'strange', 'determine', 'connect', 'share', 'parent', 'dollar', 'repeat', 'time', 'family', 'settle', 'ocean', 'sudden', 'camp', 'nature', 'particular', 'paragraph', 'operate', 'tube', 'short', 'ground', 'bar', 'colony', 'kill', 'wing', 'night', 'pose', 'master', 'told', 'hand', 'create', 'track', 'pretty', 'wear', 'west', 'iron', 'air', 'corner', 'silent', 'close', 'century', 'observe', 'glad', 'collect', 'suit', 'gas', 'sentence', 'phrase', 'beat', 'famous', 'hold', 'music', 'star', 'spring', 'size', 'surface', 'walk', 'stone', 'square', 'organ', 'count', 'cent', 'little', 'hot', 'danger', 'yard', 'equate', 'consonant', 'love', 'weather', 'hit', 'depend', 'major', 'represent', 'solve', 'continue', 'require', \"don't\", 'pull', 'include', 'describe', 'engine', 'instant', 'wave', 'oil', 'carry', 'verb', 'machine', 'summer', 'ear', 'deal', 'wife', 'fruit', 'seat', 'stop', 'language', 'soft', 'write', 'slip', 'people', 'fear', 'sing', 'heart', 'build', 'corn', 'free', 'bottom', 'value', 'six', 'band', 'rose', 'foot', 'slow', 'letter', 'money', 'dress', 'book', 'country', 'day', 'wood', 'low', 'sleep', 'mile', 'dry', 'wide', 'am', 'capital', 'bell', 'invent', 'fat', 'product', 'hear', 'temperature', 'thank', 'similar', 'tool', 'led', 'bought', 'bone', 'tail', 'agree', 'climb', 'prove', 'straight', 'death', 'lost', 'shell', 'industry', 'war', 'rich', 'win', 'mine', 'laugh', 'sound', 'original', 'brought', 'month', 'crop', 'draw', 'half', 'island', 'body', 'student', 'eight', 'age', 'supply', 'past', 'experiment', 'complete', 'ago', 'page', 'mouth', 'wait', 'plane', 'edge', 'rope', 'ice', 'usual', 'quiet', 'speak', 'spend', 'yellow', 'silver', 'radio', 'farm', 'dictionary', 'quart', 'meat', 'total', 'populate', 'fight', 'base', 'print', 'sea', 'exact', 'method', 'ride', 'eye', 'home', 'baby', 'sense', 'equal', 'boat', 'cook', 'map', 'word', 'minute', 'separate', 'serve', 'gone', 'twenty', 'term', 'fig', 'post', 'thousand', 'hole', 'press', 'liquid', 'choose', 'east', 'sit', 'column', 'travel', 'port', 'duck', 'course', 'try', 'brown', 'city', 'king', 'ease', 'skill', 'card', 'fraction', 'bad', 'lady', 'measure', 'busy', 'kept', 'send', 'heavy', 'search', 'tie', 'crowd', 'push', 'feet', 'pair', 'tell', 'select', 'branch', 'event', 'hurry', 'effect', 'step', 'save'}\n",
    "print(len(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words and common words should be mutually exclusive\n",
    "assert len(stop_words.intersection(common_words)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words for three topics are now defined. The words or phrases for the topics were created from https://relatedwords.org/relatedto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# Vehicle words (class 0)\n",
    "vehicle_words = {'motorcycle', 'headlight', 'climate change', 'glove compartment', 'coupe', 'motor vehicle', 'electric car', 'hatchback', 'sport utility vehicle', 'cab', 'jeep', 'van', 'car horn', 'truck', 'stock car', 'automobile', 'bumper', 'passenger', 'diesel', 'rear window', 'high gear', 'taxi', 'vehicle', 'motorcar', 'bus', 'suv', 'roadster', 'limousine', 'mercedes', 'alternator', 'backseat', 'air pollution', 'motor', 'wheel', 'garage'}\n",
    "print(len(vehicle_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# Internet words (class 1)\n",
    "internet_words = {'intranet', 'ftp', 'instant messaging', 'offline', 'web', 'google', 'web server', 'blogging', 'hyperlink', 'voip', 'ip address', 'websites', 'online', 'facebook', 'file sharing', 'twitter', 'www', 'youtube', 'broadband', 'world wide web', 'cyber', 'microsoft', 'social network', 'media', 'email', 'myspace', 'webcam', 'peer-to-peer', 'computer network', 'website', 'web page', 'web site', 'web browser', 'multimedia', 'cyberspace', 'http'}\n",
    "print(len(internet_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "# Garden words (class 2)\n",
    "garden_words = {'yard', 'horticultural', 'plant', 'rose garden', 'flower', 'landscape', 'patio', 'nature', 'compost heap', 'gardening', 'courtyard', 'rockery', 'tree', 'terrace', 'verbena', 'grass', 'hellebore', 'meadow', 'flower garden', 'park', 'botanical garden', 'pergola', 'hydrangea', 'land', 'herb garden', 'landscaping', 'gardener', 'ornamental', 'rosebush', 'backyard', 'wildflower', 'fountain', 'topiary', 'vegetable garden', 'orchard', 'lawn', 'kitchen garden', 'agriculture'}\n",
    "print(len(garden_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761\n"
     ]
    }
   ],
   "source": [
    "# Remove topic words from the common words\n",
    "common_words = common_words.difference(vehicle_words).difference(internet_words).difference(garden_words)\n",
    "print(len(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens for each class\n",
    "class_words = [\n",
    "    vehicle_words,\n",
    "    internet_words,\n",
    "    garden_words\n",
    "]\n",
    "\n",
    "class_names = [\"vehicle\", \"internet\", \"garden\"]\n",
    "\n",
    "# Probability of tokens from the class appearing\n",
    "p_class = [0.4, 0.2, 0.05]\n",
    "assert len(class_words) == len(p_class)\n",
    "\n",
    "# Mean number of words from each class\n",
    "lambda_class = [2, 1, 3]\n",
    "assert len(lambda_class) == len(p_class)\n",
    "\n",
    "# Mean number of stopwords appearing\n",
    "lambda_stop = 2\n",
    "\n",
    "# Mean number of common words appearing\n",
    "lambda_common = 2\n",
    "\n",
    "# Number of synthetic documents to generate\n",
    "n_documents = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_elements_from_set(s, n):\n",
    "    \"\"\"Returns n random elements from set s (with replacement).\"\"\"\n",
    "    \n",
    "    # Preconditions\n",
    "    assert isinstance(s, set), f\"Expected a set, got {type(s)}\"\n",
    "    assert isinstance(n, int), f\"Expected an int, got {type(n)}\"\n",
    "    assert 0 <= n, f\"Invalid number of elements {n}\"\n",
    "    \n",
    "    elements = [random.choice(list(s)) for _ in range(n)]\n",
    "    \n",
    "    # Postcondition\n",
    "    assert len(elements) == n\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_text():\n",
    "    \"\"\"Generates a random piece of text.\"\"\"\n",
    "    \n",
    "    # Stop words\n",
    "    text = random_elements_from_set(stop_words, np.random.poisson(lambda_stop))\n",
    "    \n",
    "    # Common words\n",
    "    text.extend(random_elements_from_set(common_words, np.random.poisson(lambda_common)))\n",
    "    \n",
    "    # Words from each class\n",
    "    class_present = []\n",
    "    for i in range(len(class_words)):\n",
    "        \n",
    "        if random.random() <= p_class[i]:\n",
    "            \n",
    "            # Select the topic words ensuring that words are generated\n",
    "            topic_words = []\n",
    "            while len(topic_words) == 0:\n",
    "                topic_words = random_elements_from_set(class_words[i], np.random.poisson(lambda_class[i]))\n",
    "            \n",
    "            # Add the topic words to the text\n",
    "            text.extend(topic_words)\n",
    "            class_present.append(1)\n",
    "        else:\n",
    "            class_present.append(0)\n",
    "        \n",
    "    # Postconditions\n",
    "    assert isinstance(text, list)\n",
    "    assert len(class_present) == len(class_words)\n",
    "    \n",
    "    return text, class_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['men', 'shows', 'fire', 'excite'], [0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show an example of what the generate_random_text() function produces\n",
    "generate_random_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the corpus is generated, which is a collection of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus(n_docs):\n",
    "    \"\"\"Generate a corpus of documents.\"\"\"\n",
    "    \n",
    "    # Preconditions\n",
    "    assert isinstance(n_docs, int)\n",
    "    assert n_docs > 0\n",
    "    \n",
    "    texts = []\n",
    "    class_labels = []\n",
    "    \n",
    "    for i in range(n_docs):\n",
    "        words, labels = generate_random_text()\n",
    "        \n",
    "        # The topic can contain multiple words so this step separates them\n",
    "        tokens = \" \".join(words)\n",
    "        texts.append(tokens)\n",
    "        class_labels.append(labels)\n",
    "        \n",
    "    class_labels = np.array(class_labels)\n",
    "    \n",
    "    # Postconditions\n",
    "    assert isinstance(texts, list)\n",
    "    assert len(texts) == n_docs\n",
    "    assert class_labels.shape == (n_docs, len(class_words))\n",
    "    \n",
    "    return texts, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the corpus\n",
    "texts, class_labels = generate_corpus(n_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see force provide\n",
      "after f went knew\n"
     ]
    }
   ],
   "source": [
    "# Show examples of texts\n",
    "print(texts[0])\n",
    "print(texts[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the number of tokens in a document is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the simplistic way the texts are constructed a simple white space tokeniser can be used\n",
    "number_of_tokens = [len(t.split(\" \")) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(number_of_tokens, bins=np.arange(max(number_of_tokens)+1) - 0.5)\n",
    "plt.xlabel('Number of tokens in a document')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the machine learning pipeline is to convert the textual data to numeric values by counting the number of times a token appears in each document. Stop words are ignored because they are deemed 'noise' and don't provide information as to which topic a text contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise, remove stop words and count token occurrences\n",
    "vectorizer = CountVectorizer(stop_words=list(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts shape = (10000, 870)\n",
      "y shape = (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "counts = vectorizer.fit_transform(texts)\n",
    "print(f\"counts shape = {counts.shape}\")\n",
    "\n",
    "y = class_labels\n",
    "print(f\"y shape = {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows\n",
    "assert counts.shape[0] == n_documents\n",
    "\n",
    "# Check none of the stop words have been counted\n",
    "assert len(set(vectorizer.get_feature_names()).intersection(stop_words)) == 0\n",
    "\n",
    "# Check the shape of the labels\n",
    "assert y.shape[0] == n_documents\n",
    "assert y.shape[1] == len(class_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts are normalised by converting the values to TF-IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (10000, 870)\n"
     ]
    }
   ],
   "source": [
    "# Convert the counts to TF-IDF scores\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "X = transformer.fit_transform(counts)\n",
    "print(f\"X shape = {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix and label matrix are together now divided into training and test sets. The training set will be used for training the classifiers. The test set will only be used at the end to measure the performance of the chosen classifer. The performance on the test set gives an indication as to how well the classifier will work on unseen data provided it is sufficiently similar to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial classifier selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section a range of multilabel classifiers are checked to see whether they show promising performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2896468790718645"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "y_train_dt_pred = cross_val_predict(dt_clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380404176331385"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_dt_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rf_pred = cross_val_predict(rf_clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469527744186177"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_rf_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most promising classifier from the previous section is now tuned by performing a parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': [6, 8, 10, 12, 14, 18, 20, None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(dt_clf, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'max_depth': [6, 8, 10, 12, 14, 18, 20, None],\n",
       "                          'splitter': ['best', 'random']}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': None, 'splitter': 'random'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation using the best estimator\n",
    "y_train_pred = cross_val_predict(grid_search.best_estimator_, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_performance(y, y_pred):\n",
    "    \"\"\"Summarise the performance of the classifier.\"\"\"\n",
    "    \n",
    "    # Preconditions\n",
    "    assert y.shape == y_pred.shape\n",
    "    \n",
    "    print(f\"Precision: {precision_score(y, y_pred, average='macro')}\")\n",
    "    print(f\"Recall: {recall_score(y, y_pred, average='macro')}\")\n",
    "    print(f\"f1-score: {f1_score(y, y_pred, average='macro')}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9283956508675609\n",
      "Recall: 0.7839434645534936\n",
      "f1-score: 0.8467988115849555\n"
     ]
    }
   ],
   "source": [
    "summarise_performance(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the optimal classifier has been determined from the possible classifiers given the range of parameters, the features that should be used are now selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.00399512, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00066644, 0.        ,\n",
       "       0.        , 0.0074314 , 0.        , 0.        , 0.        ,\n",
       "       0.00032347, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The estimator produces scores for the features\n",
    "grid_search.best_estimator_.feature_importances_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features based on the model\n",
    "model = SelectFromModel(grid_search.best_estimator_, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6700x870 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24741 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6700x89 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9468 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note how the number of features is reduced by this selection phase\n",
    "X_train_fs = model.transform(X_train)\n",
    "X_train_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal classifier given the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'max_depth': [6, 8, 10, 12, 14, 18, 20, None],\n",
       "                          'splitter': ['best', 'random']}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A grid search is now performed again, this time with the training data with the\n",
    "# reduced set of features\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': [6, 8, 10, 12, 14, 18, 20, None]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(dt_clf, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': None, 'splitter': 'random'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9413969879850071\n",
      "Recall: 0.8071378107140464\n",
      "f1-score: 0.8664832750083917\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation using the best estimator\n",
    "y_train_pred = cross_val_predict(grid_search.best_estimator_, X_train_fs, y_train, cv=3)\n",
    "summarise_performance(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifer per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the approaches above, a single model was trained to produce a vector of labels for each text. In this section, a classifier is trained per label and the results combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclassifier(classifier, X, y):\n",
    "    \"\"\"Train a classifier per label.\"\"\"\n",
    "    \n",
    "    # Preconditions\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    # Matrix of predictions for each label\n",
    "    y_pred = np.zeros(y.shape)\n",
    "    \n",
    "    # Number of labels\n",
    "    num_labels = y.shape[1]\n",
    "    \n",
    "    # List of classifiers, one for each label\n",
    "    classifiers = [clone(classifier) for _ in range(num_labels)]\n",
    "    \n",
    "    # Walk through each column and perform k-fold cross-validation and prediction\n",
    "    for label_idx in range(num_labels):\n",
    "        y_pred[:,label_idx] = cross_val_predict(classifiers[label_idx], X, y[:,label_idx], cv=3)\n",
    "    \n",
    "    # Return the predictions\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9951780317960847\n",
      "Recall: 0.9386781890147406\n",
      "f1-score: 0.9649055198461202\n"
     ]
    }
   ],
   "source": [
    "y_pred_bernoulli = multiclassifier(BernoulliNB(), X_train, y_train)\n",
    "summarise_performance(y_train, y_pred_bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9838660446131772\n",
      "Recall: 0.9784266071115783\n",
      "f1-score: 0.9811126325592353\n"
     ]
    }
   ],
   "source": [
    "y_pred_decision_tree = multiclassifier(DecisionTreeClassifier(), X_train, y_train)\n",
    "summarise_performance(y_train, y_pred_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9986168741355463\n",
      "Recall: 0.9836223506743739\n",
      "f1-score: 0.9909119375786043\n"
     ]
    }
   ],
   "source": [
    "y_pred_random_forest = multiclassifier(RandomForestClassifier(), X_train, y_train)\n",
    "summarise_performance(y_train, y_pred_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_and_training(classifier, X, y):\n",
    "    \n",
    "    # Matrix of predictions for each label\n",
    "    y_pred = np.zeros(y.shape)\n",
    "    \n",
    "    # Number of labels\n",
    "    num_labels = y.shape[1]\n",
    "    \n",
    "    # List of classifiers, one for each label\n",
    "    classifiers = [clone(classifier) for _ in range(num_labels)]\n",
    "    classifiers_all_data = [clone(classifier) for _ in range(num_labels)]\n",
    "    \n",
    "    # Feature selection models\n",
    "    models = [None for _ in range(num_labels)]\n",
    "    \n",
    "    # Walk through each column and perform k-fold cross-validation and prediction\n",
    "    for label_idx in range(num_labels):\n",
    "        \n",
    "        # Train the classifier to find features of importance\n",
    "        classifiers[label_idx].fit(X, y[:,label_idx])\n",
    "        models[label_idx] = SelectFromModel(classifiers[label_idx], prefit=True)\n",
    "        \n",
    "        # Retain the required features\n",
    "        X_fs = models[label_idx].transform(X)\n",
    "        \n",
    "        # Perform cross-validation prediction\n",
    "        y_pred[:,label_idx] = cross_val_predict(classifiers[label_idx], X_fs, y[:,label_idx], cv=3)\n",
    "    \n",
    "        # Train classifier using all data\n",
    "        classifiers_all_data[label_idx] = classifiers_all_data[label_idx].fit(X_fs, y[:,label_idx])\n",
    "        \n",
    "    return models, classifiers_all_data, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9994957135653051\n",
      "Recall: 0.9894026974951831\n",
      "f1-score: 0.9943634270452493\n"
     ]
    }
   ],
   "source": [
    "models, classifiers_all_data, y_pred_random_forest = feature_selection_and_training(RandomForestClassifier(), X_train, y_train)\n",
    "summarise_performance(y_train, y_pred_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiclassifier(models, classifiers_all_data, X):\n",
    "    \"\"\"Predict labels using feature selection and classification models.\"\"\"\n",
    "    \n",
    "    # Number of labels\n",
    "    num_labels = len(models)\n",
    "    \n",
    "    # Matrix of predictions for each label\n",
    "    y_pred = np.zeros((X.shape[0], num_labels))\n",
    "    \n",
    "    for label_idx in range(num_labels):\n",
    "        \n",
    "        # Select the required features\n",
    "        X_fs = models[label_idx].transform(X)\n",
    "        \n",
    "        # Perform prediction\n",
    "        y_pred[:,label_idx] = classifiers_all_data[label_idx].predict(X_fs)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "f1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_multiclassifier = predict_multiclassifier(models, classifiers_all_data, X_train)\n",
    "\n",
    "# Overfitting has occurred\n",
    "print(f\"Precision: {precision_score(y_train, y_pred_multiclassifier, average='macro')}\")\n",
    "print(f\"Recall: {recall_score(y_train, y_pred_multiclassifier, average='macro')}\")\n",
    "print(f\"f1-score: {f1_score(y_train, y_pred_multiclassifier, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that feature selection has been performed, the features can be determined. Let's see how many of the features correspond to the tokens from the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'limousine', 'bumper', 'stock', 'air', 'automobile', 'bus', 'cab', 'coupe', 'van', 'wheel', 'pollution', 'rear', 'truck', 'motorcar', 'roadster', 'hatchback', 'horn', 'motorcycle', 'climate', 'gear', 'diesel', 'passenger', 'headlight', 'taxi', 'car', 'change', 'motor', 'window', 'compartment', 'sport', 'alternator', 'utility', 'glove', 'jeep', 'mercedes', 'vehicle', 'garage', 'suv', 'backseat', 'electric'}\n",
      "{'email', 'facebook', 'cyberspace', 'website', 'instant', 'peer', 'voip', 'messaging', 'world', 'file', 'computer', 'twitter', 'server', 'google', 'broadband', 'cyber', 'network', 'address', 'site', 'sharing', 'webcam', 'microsoft', 'web', 'media', 'youtube', 'car', 'http', 'motor', 'myspace', 'page', 'hyperlink', 'multimedia', 'ftp', 'ip', 'wide', 'browser', 'vehicle', 'online', 'social', 'intranet', 'websites', 'offline', 'www', 'blogging'}\n",
      "{'lawn', 'agriculture', 'fountain', 'ten', 'botanical', 'flower', 'tree', 'kitchen', 'backyard', 'grass', 'hellebore', 'vegetable', 'hydrangea', 'courtyard', 'heap', 'compost', 'garden', 'horticultural', 'park', 'terrace', 'rockery', 'herb', 'rosebush', 'topiary', 'motor', 'ornamental', 'land', 'rose', 'yard', 'orchard', 'gardener', 'nature', 'landscaping', 'plant', 'gardening', 'meadow', 'pergola', 'landscape', 'patio', 'verbena', 'wildflower'}\n"
     ]
    }
   ],
   "source": [
    "num_tokens_correct = []\n",
    "num_tokens_incorrect = []\n",
    "\n",
    "for class_i, tokens in enumerate(class_words):\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    model_support = models[class_i].get_support()\n",
    "    \n",
    "    selected_features = set([feature_names[i] for i in range(len(feature_names)) if model_support[i]])    \n",
    "    print(selected_features)\n",
    "    \n",
    "    num_tokens_correct.append(len(selected_features.intersection(tokens)))\n",
    "    num_tokens_incorrect.append(len(selected_features.difference(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Number of correct tokens</th>\n",
       "      <th>Number of incorrect tokens</th>\n",
       "      <th>Proportion correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>internet</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garden</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.756098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic  Number of correct tokens  Number of incorrect tokens  \\\n",
       "0   vehicle                        25                          15   \n",
       "1  internet                        25                          19   \n",
       "2    garden                        31                          10   \n",
       "\n",
       "   Proportion correct  \n",
       "0            0.625000  \n",
       "1            0.568182  \n",
       "2            0.756098  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Topic\": class_names,\n",
    "    \"Number of correct tokens\": num_tokens_correct,\n",
    "    \"Number of incorrect tokens\": num_tokens_incorrect,\n",
    "    \"Proportion correct\": np.array(num_tokens_correct) / (np.array(num_tokens_correct) + np.array(num_tokens_incorrect))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final performance measure on held-out test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the performance of the chosen classifier on the held-out test set is determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3300x89 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4746 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain the selected features\n",
    "X_test_fs = model.transform(X_test)\n",
    "X_test_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9340755580245083\n",
      "Recall: 0.8103474408640531\n",
      "f1-score: 0.8655711076525584\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier using all of the available training data\n",
    "grid_search.best_estimator_.fit(X_train_fs, y_train)\n",
    "\n",
    "# Predict the labels based on the test data set's feature matrix\n",
    "y_pred = grid_search.best_estimator_.predict(X_test_fs)\n",
    "\n",
    "# Measure the performance of the classifier on the test set\n",
    "summarise_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.9997536338999753\n",
      "f1-score: 0.9998767714109674\n"
     ]
    }
   ],
   "source": [
    "y_pred_multiclassifier = predict_multiclassifier(models, classifiers_all_data, X_test)\n",
    "summarise_performance(y_test, y_pred_multiclassifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
